Design Decisions
================

Maintainability
---------------

* Programming to interfaces: The functionality for keeping the keys in insertion
  order for reproducible results is factored out into a struct, which follows a
  similar interface to the standard library's linked lists. The key type has a
  type definition to simplify changing to different key types, whose merits I
  detail below.
* Method length: I've kept methods short and simple and added comments to ease
  cognitive load. The code follows the patterns in the Go Blog's Pipelines
  article closely.
* Separation of concerns: The pipeline pattern allows to separate the stages
  cleanly while also allowing reasonable performance.

Scalability
-----------

* Time complexity: The algorithm is linear over the number of words and has
  complexity O(n * log(n)) in the number of characters per word (because of the
  sorting step). For very large word lengths, using an array or a map as a key
  which counts the occurrences of each letter might be faster (complexity O(n)).
* Memory complexity: All the words have to be kept in memory until the end,
  before anagrams can be output, because the last line could be an anagram to
  the first line. Preprocessing the word list to order by word size would allow
  to output anagrams whenever the word size goes up and would also allow to
  prune single words at that point.
  Another alternative would be to write results to a file and to remember file
  offsets where additional anagrams can be appended to word lists.

Performance
-----------

* Concurrency: While the time complexity (also that of my draft I submitted on
  Wednesday) in theory allows scaling to 100 billion words, parallel anagram
  searching will allow for more reasonable time spans. For simplicity I run all
  Go routines in a single process, as addressing that much physical memory is
  possible with high-end 64-bit servers.
* Pipelines: A simple approach for running computations in parallel and merging
  their results is detailed in the [Pipelines article of the Go
  blog](https://blog.golang.org/pipelines), which is the approach I've used to
  implement my solution.. 
* Possible optimizations for sample input: If we were to assume (as holds true
  for the sample input) that all words are less than four characters long, then
  we could use a sorting network to calculate the map's key, which would allow
  doing this for several words in parallel on the GPU and allow for impressive
  speedups.

Caveats
-------

For simplicity I assume ASCII encoding, regard equal words as anagrams and keep
anagrams sensitive to the number of spaces and to case.
